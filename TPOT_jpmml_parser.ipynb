{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris.data[0:5], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (38, 4), (112,), (38,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975757575758\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load tpot_iris_pipeline.py\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'class' in the data file\n",
    "#tpot_data = np.recfromcsv('PATH/TO/DATA/FILE', delimiter='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "#tpot_data = np.hstack((iris.data, np.expand_dims(iris.target, axis=1)))\n",
    "#features = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('class'), axis=1)\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "training_features, testing_features, training_classes, testing_classes = \\\n",
    "    train_test_split(features, target, random_state=42)\n",
    "\n",
    "exported_pipeline = make_pipeline(\n",
    "    RBFSampler(gamma=0.55),\n",
    "    SelectPercentile(percentile=8, score_func=f_classif),\n",
    "    ExtraTreesClassifier(criterion=\"entropy\", max_features=0.44, n_estimators=500)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_classes)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(exported_pipeline.fit(training_features, training_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn2pmml.decoration import ContinuousDomain\n",
    "import pandas\n",
    "import sklearn_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7189c7c61685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#      [SelectPercentile(percentile=8, score_func=f_classif)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ),\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"Species\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cameron2/anaconda/lib/python2.7/site-packages/sklearn_pandas/dataframe_mapper.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, features, sparse)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             features = [(columns, _build_transformer(transformers))\n\u001b[0;32m---> 49\u001b[0;31m                         for (columns, transformers) in features]\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "iris_mapper = sklearn_pandas.DataFrameMapper([\n",
    "    ([\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"], \n",
    "#      RBFSampler(gamma=0.55)),\n",
    "#      [ContinuousDomain(), PCA(n_components = 3)]\n",
    "#      [ContinuousDomain(), RBFSampler(gamma=0.55)]),\n",
    "#      [SelectPercentile(percentile=8, score_func=f_classif)]\n",
    "    ),\n",
    "    (\"Species\", None)\n",
    "])\n",
    "\n",
    "# iris_classifier = sklearn.linear_model.LogisticRegressionCV()\n",
    "iris_classifier = ExtraTreesClassifier(criterion=\"entropy\", max_features=0.44, n_estimators=500)\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pandas.concat((pandas.DataFrame(iris.data[:, :], columns = [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]), pandas.DataFrame(iris.target, columns = [\"Species\"])), axis = 1)\n",
    "iris = iris_mapper.fit_transform(iris_df)\n",
    "iris_X = iris[:, :-1]\n",
    "iris_y = iris[:, -1]\n",
    "\n",
    "iris_classifier.fit(iris_X, iris_y)\n",
    "\n",
    "sklearn2pmml(iris_classifier, iris_mapper, \"cam_iris.pmml\", with_repr = True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "print iris.data.shape\n",
    "print iris_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print iris_X.shape\n",
    "print iris_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08243959,  0.07485807,  0.13500864, ...,  0.05458325,\n",
       "         0.10707913,  0.        ],\n",
       "       [-0.08013961,  0.14142125,  0.08167507, ...,  0.07093541,\n",
       "         0.12377177,  0.        ],\n",
       "       [-0.0735397 ,  0.14130325,  0.09460401, ...,  0.09117099,\n",
       "         0.13857378,  0.        ],\n",
       "       ..., \n",
       "       [ 0.093769  ,  0.05136669,  0.12508146, ...,  0.12087511,\n",
       "        -0.07438504,  2.        ],\n",
       "       [ 0.12386193,  0.11440241,  0.05728974, ...,  0.05331696,\n",
       "        -0.10202548,  2.        ],\n",
       "       [ 0.05633671, -0.04819906,  0.11233171, ...,  0.07447886,\n",
       "        -0.14084731,  2.        ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('python: ', '2.7.11')\n",
      "('sklearn: ', '0.17.1')\n",
      "('sklearn.externals.joblib:', '0.9.4')\n",
      "('sklearn_pandas: ', '1.1.0')\n",
      "('sklearn2pmml: ', '0.11.1')\n",
      "java -cp /Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/guava-19.0.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/istack-commons-runtime-2.21.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jaxb-core-2.2.11.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jaxb-runtime-2.2.11.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jcommander-1.48.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jpmml-converter-1.1.0.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jpmml-sklearn-1.1.1.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/jpmml-xgboost-1.1.0.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/pmml-agent-1.3.1.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/pmml-model-1.3.1.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/pmml-model-metro-1.3.1.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/pmml-schema-1.3.1.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/pyrolite-4.13.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/serpent-1.12.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/slf4j-api-1.7.21.jar:/Users/cameron2/.local/lib/python2.7/site-packages/sklearn2pmml/resources/slf4j-jdk14-1.7.21.jar org.jpmml.sklearn.Main --pkl-estimator-input /var/folders/8b/9jwdlts97ksbwxf20wtv9jbm0000gs/T/estimator-txAG7c.pkl.z --repr-estimator LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0) --pkl-mapper-input /var/folders/8b/9jwdlts97ksbwxf20wtv9jbm0000gs/T/mapper-sJt_cf.pkl.z --repr-mapper DataFrameMapper(features=[(['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width'], TransformerPipeline(steps=[('continuousdomain', ContinuousDomain(invalid_value_treatment='return_invalid')), ('pca', PCA(copy=True, n_components=3, whiten=False))])), ('Species', None)],\n",
      "        sparse=False) --pmml-output LogisticRegressionIris.pmml\n",
      "('Preserved joblib dump file(s): ', '/var/folders/8b/9jwdlts97ksbwxf20wtv9jbm0000gs/T/estimator-txAG7c.pkl.z /var/folders/8b/9jwdlts97ksbwxf20wtv9jbm0000gs/T/mapper-sJt_cf.pkl.z')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 1: feature engineering\n",
    "#\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn2pmml.decoration import ContinuousDomain\n",
    "\n",
    "import pandas\n",
    "import sklearn_pandas\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pandas.concat((pandas.DataFrame(iris.data[:, :], columns = [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]), pandas.DataFrame(iris.target, columns = [\"Species\"])), axis = 1)\n",
    "\n",
    "iris_mapper = sklearn_pandas.DataFrameMapper([\n",
    "    ([\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"], \n",
    "     [ContinuousDomain(), PCA(n_components = 3)]),\n",
    "    (\"Species\", None)\n",
    "])\n",
    "\n",
    "iris = iris_mapper.fit_transform(iris_df)\n",
    "\n",
    "\n",
    "#\n",
    "# Step 2: training a logistic regression model\n",
    "#\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "iris_X = iris[:, :-1]\n",
    "iris_y = iris[:, -1]\n",
    "\n",
    "iris_classifier = LogisticRegressionCV()\n",
    "iris_classifier.fit(iris_X, iris_y)\n",
    "\n",
    "#\n",
    "# Step 3: conversion to PMML\n",
    "#\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "sklearn2pmml(iris_classifier, iris_mapper, \"LogisticRegressionIris.pmml\", with_repr = True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
